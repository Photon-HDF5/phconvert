{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbed2cd8-d6da-4e8c-893b-5956921fdea0",
   "metadata": {},
   "source": [
    "# Convert PicoQuant ns-ALEX files to Photon-HDF5\n",
    "\n",
    "<p class=\"lead\">This <a href=\"https://jupyter.org/\">Jupyter notebook</a>\n",
    "will guide you through the conversion of a ns-ALEX data file from PicoQuant formats <b>(PTU, HT3, PT3)</b>\n",
    "to <a href=\"http://photon-hdf5.org\">Photon-HDF5</a> format. For more info on how to edit\n",
    "a jupyter notebook refer to <a href=\"http://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb#Overview-of-the-Notebook-UI\">this example</a>.</p>\n",
    "\n",
    "*Please send feedback and report any problem to the \n",
    "[Photon-HDF5 google group](https://groups.google.com/forum/#!forum/photon-hdf5).*\n",
    "\n",
    "# 1. How to run it?\n",
    "\n",
    "The notebook is composed by \"text cells\", such as this paragraph, and \"code cells\"\n",
    "containing the code to be executed (and identified by an `In [ ]` prompt). \n",
    "To execute a code cell, select it and press **SHIFT+ENTER**. \n",
    "To modify an cell, click on it to enter \"edit mode\" (indicated by a green frame), \n",
    "then type.\n",
    "\n",
    "You can run this notebook directly online (for demo purposes), or you can \n",
    "run it on your on desktop. For a local installation please refer to:\n",
    "\n",
    "- [Jupyter Notebook Quick-Start Guide](http://jupyter-notebook-beginner-guide.readthedocs.org) \n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "Please run each each code cell using <b>SHIFT+ENTER</b>.\n",
    "</div>\n",
    "\n",
    "# 2. Prepare the data file\n",
    "\n",
    "## 2.1 Import modules\n",
    "\n",
    "First we need to import ``phconvert`` as well as a few other standard python modules into the python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b874ca-34f4-478a-bd66-19896eeef85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import phconvert as phc\n",
    "print('phconvert version: ' + phc.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09f5d3-0353-42ae-8bf8-1c9426a13107",
   "metadata": {},
   "source": [
    "## 2.2 Upload the data file\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Note:</b> if you are running the notebook locally skip to section [<b>2.3</b>].\n",
    "</div>\n",
    "\n",
    "Before starting, you have to upload a data file to be converted to Photon-HDF5.\n",
    "You can use one of our example data files available\n",
    "[on figshare](http://dx.doi.org/10.6084/m9.figshare.1455963). \n",
    "\n",
    "To upload a file (up to 35 MB) switch to the \"Home\" tab in your browser, \n",
    "click the **Upload** button and select the data file\n",
    "and wait until the upload completes.\n",
    "To upload files larger than 35 MB (like some of our example files) please use the \n",
    "[Upload notebook](Upload data files.ipynb) instead.\n",
    "\n",
    "Once the file is uploaded, come back here and follow the instructions below.\n",
    "\n",
    "## 2.3 Select the file\n",
    "\n",
    "Specify the input data file in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa4e8d-0f81-4894-b92d-16ac640e6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/Cy3+Cy5_diff_PIE-FRET.ptu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e778cede-48b6-44b5-b68c-981f7b6befaa",
   "metadata": {},
   "source": [
    "The next cell will check if the `filename` location is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75d22f-f16f-4219-a9ec-7f5335a4068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(filename):\n",
    "    print(\"File found, you can proceed\")\n",
    "else:\n",
    "    if os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"'{filename}' is not a file\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"'{filename}' does not exist\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "294abf2d-fc66-4385-b9cb-886fe0b5ac2a",
   "metadata": {},
   "source": [
    "If there is an error, adjust the `filename` cell to the correct location\n",
    "\n",
    "## 3.1 Load the file\n",
    "\n",
    "Now we can load the data into the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb81c3-6521-4a54-8bb6-c63cd2f5e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, metadata = phc.loader.loadfile_ptu(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d5315-98e0-4439-97a2-a38f45882939",
   "metadata": {},
   "source": [
    "There are a number of usual (most of them are **required**) metadata fields in photon-HDF5 that cannot \n",
    "be determined from the .ptu file.\n",
    "Therefore `loader.loadfile_ptu` inserts these fields into the dictionary with `None` values to indicate\n",
    "to the user that these fields are expected, and must be filled out by the user.\n",
    "\n",
    "The function `phc.helperfuncs.report_nones` is a convenience function that prints all such `None` fields\n",
    "in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c21ec2-0255-4408-ac42-212a9ba25c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "phc.helperfuncs.report_nones(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6e54f-13f1-439e-8fb9-98910caeb00a",
   "metadata": {},
   "source": [
    "#### 3.2.1 Metadata\n",
    "\n",
    "Now we fill out some metadata so the nature of the experiment can be known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39461eca-1719-490e-a6ef-6c05f95d107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample fields\n",
    "author = 'John Doe'\n",
    "author_affiliation = 'Research Institution'\n",
    "description = 'A demonstrative measurement.'\n",
    "sample_name = 'A demonstrative fluorescently labeled construct'\n",
    "dye_names = 'dyeA, dyeB'\n",
    "buffer_name = 'A standard buffer'\n",
    "measurement_type = 'generic' # can be 'smFRET', 'smFRET-nsALEX', smFRET-usALEX' etc.\n",
    "\n",
    "sample = dict(\n",
    "    sample_name=sample_name,\n",
    "    dye_names=dye_names,\n",
    "    buffer_name=buffer_name,\n",
    "    num_dyes = len(dye_names.split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e782e69-561d-4a76-96cd-5816401312b9",
   "metadata": {},
   "source": [
    "#### 3.2.2 Emission parameters\n",
    "\n",
    "As the acquisition software does not know about all the\n",
    "filters and various distances between detectors etc.,\n",
    "it is necessary to add these experimental configuration settings\n",
    "in the jupyter noteboo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0fe3c-33d9-428a-ad52-8f613d675c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "excitation_wavelengths = np.array([488e-9, 632e-9])\n",
    "excitation_cw = np.array([False, False])\n",
    "excitation_alternated = np.array([False, False])\n",
    "detection_wavelengths = np.array([580e-9, 690e-9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdfbfb-37b7-4887-a8da-1464b35e3a23",
   "metadata": {},
   "source": [
    "Populate the data dictionary with the various metadata fields in their correct names/positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5910e-69f0-49f9-96a0-4e729b96d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = description\n",
    "data['sample'] = sample\n",
    "data['identity']['author'] = author\n",
    "data['identity']['author_affiliation'] = author_affiliation\n",
    "phc.helperfuncs.fill_measurement_type(data, measurement_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b90d20-ae2c-4680-b428-5a58952a39d0",
   "metadata": {},
   "source": [
    "The detector indexes used in the file are recorded in the\n",
    "`/photon_data/measurement_specs/detectors_specs/spectral_polarization_split_chN`\n",
    "key in the data dictionary.\n",
    "\n",
    "This key must be removed as it is not a valid field in photon-HDF5.\n",
    "This field is exported by the `loader.loadfile_ptu` function because\n",
    "the detectors must be assigned to several field, namely:\n",
    "\n",
    "- `spectral_ch1`, `spectral_ch2` ... etc\n",
    "- `polarization_ch1`, `polarization_ch2` ... etc\n",
    "- `split_ch1`, `split_ch2` ... etc\n",
    "\n",
    "if for any of these categories has only one channel/photons are not sorted in the\n",
    "given way by the setup, it can be ommitted.\n",
    "\n",
    "Since `phconvert` has no way of knowing how to assign detectors to these fields,\n",
    "it stores all of them in a 'hint' field, so the user can at least know what the\n",
    "detectors are, and can assign them appropriately.\n",
    "\n",
    "The cell bellow shows all the detector indexes in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c75a58-785f-4219-8cac-8fc0882163f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors_specs = data['photon_data']['measurement_specs']['detectors_specs']\n",
    "setup = data['setup']\n",
    "detectors_ids = detectors_specs.pop('spectral_polarization_split_chN')\n",
    "print(detectors_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aedc42-2d0c-412a-b33e-5d0ffefc20ce",
   "metadata": {},
   "source": [
    "Now assign the detector ids to the correct channels.\n",
    "\n",
    "The code below will be modified according to the actual detectors used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6916a-4ec8-4b7f-afed-aca2fc7bae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust according to how each detector is assigned to spectral/polarization/split channels\n",
    "detectors_specs['spectral_ch1'] = detectors_ids[:1]\n",
    "detectors_specs['spectral_ch2'] = detectors_ids[1:]\n",
    "# detectors_specs['polarization_ch1'] = detectors_ids[::2]\n",
    "# detectors_specs['polarization_ch2'] = detectors_ids[1::2]\n",
    "# detectors_specs['split_ch1'] = detectors_ids[::2]\n",
    "# detectors_specs['split_ch2'] = detectors_ids[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b835d-989f-4d8d-aabe-0833e836709f",
   "metadata": {},
   "source": [
    "If your TCSPC device adds sync photons, space-time markers, or any other sort of marker,\n",
    "these must be assigned to `non_photon_id1` `non_photon_id2` ... etc. (only a single field is needed)\n",
    "\n",
    "The `loader.loadfile_ptu` loads these into `non_photon_idN` for the same reason it uses\n",
    "`spectral_polarization_split_chN`. So assign appropriately\n",
    "\n",
    "If there are no markers, the `non_photon_idN` field will not be present in the output dictionary,\n",
    "and the `non_photon_id1` field is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6acde0-b629-4995-98c4-757267ca6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_photon = detectors_specs.pop('non_photon_idN', list())\n",
    "print(non_photon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218b74e-2577-4651-b0b8-b42cccefee9d",
   "metadata": {},
   "source": [
    "The code bellow is a \"dummy\" code, basically if markers are present, it assigns them all to sequential `non_photon_idN` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac6db2-ac71-4829-ba80-93aa324b4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if non_photon is not None and len(non_photon):\n",
    "    for i, nph in enumerate(non_photon):\n",
    "        detectors_specs[f'non_photon_id{i}'] = np.array([nph,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dcb5c7-24ca-4b0f-9266-f894f820735e",
   "metadata": {},
   "source": [
    "### 3.2.3 Emission parameters\n",
    "\n",
    "When multiple excitations are present, the period for each excitation should be specified.\n",
    "\n",
    "`phconvert` supplies a useful function for choosing the ideal range(s) for each period,\n",
    "and for visualizing the appearance of the decays, this is `plotter.alternation_hist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277e2af-bf3a-4fbe-8d69-5a80d11d85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phc.plotter.alternation_hist(data, group_dets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13d79b-1b6e-475b-b0c8-5479682ef724",
   "metadata": {},
   "source": [
    "From this plot, iterate with the cell below to find the best windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ab151-a154-4c56-88bc-f8f44f4fce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_excitation_donor = (50, 850)\n",
    "alex_excitation_acceptor = (1400, 2250)\n",
    "phc.helperfuncs.fill_alex_periods(data, alex_excitation_donor, alex_excitation_acceptor)\n",
    "phc.plotter.alternation_hist(data, group_dets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646c7ce-4a0a-4f41-8afb-c5d19cd3edd6",
   "metadata": {},
   "source": [
    "Once those field look well aligned, there may be an offset between the decays\n",
    "of different detectors due to speed of light delays.\n",
    "Therefore, the optional field `/setup/detectors/tcspc_offsets` allows each\n",
    "detector id to be given its own integer offset, in `tcspc_unit` units.\n",
    "\n",
    "Again, iterate with the cell below to allign the decays so that they are alligned\n",
    "within the excitation windows idealy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236f701-9bb1-4c31-9025-bc4b9b2d3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup['detectors']['tcspc_offsets'] = np.array([0, 75])\n",
    "phc.plotter.alternation_hist(data, group_dets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33029c47-a401-4cf1-8b11-bacb2a69f21f",
   "metadata": {},
   "source": [
    "Some final fields to fill out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc616b-2d57-429a-8776-9f157fe158e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "phc.helperfuncs.fill_setup(data)\n",
    "\n",
    "setup['excitation_wavelengths'] = excitation_wavelengths\n",
    "setup['excitation_cw'] = excitation_cw\n",
    "setup['excitation_alternated'] = excitation_alternated\n",
    "setup['detection_wavelengths'] = detection_wavelengths\n",
    "setup['detectors']['label'] = np.array(['donor','acceptor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f025f8-1084-478a-b8b1-544044acd789",
   "metadata": {},
   "source": [
    "The `report_nones` function will print out any fields you still need to fill out.\n",
    "If you have filled everything out, the cell bellow should have no output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3610e-e22d-40e0-8057-c79a93a1f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phc.helperfuncs.report_nones(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ccf75-49ce-412a-989d-1e47d8db576b",
   "metadata": {},
   "source": [
    "We store the metadata in the `user/picoquant` group so that no data is lost.\n",
    "This data will not be processed by standard photon-HDF5 readers,\n",
    "but may be helpful for human readers debugging or othewise investigating the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff40ac0-ff48-4dbb-9a19-fcd189ca0de8",
   "metadata": {},
   "source": [
    "## 4. Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c24c1c-00cc-45cd-b85e-b5197aec020b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phc.hdf5.save_photon_hdf5(data, h5_fname='testout.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa007a9-91e2-408e-9d0b-b6f2275937be",
   "metadata": {},
   "source": [
    "The conversion is complete, the remainder of the notebook is just for verifying that the file was saved correctly.\n",
    "\n",
    "## 5. Check file\n",
    "\n",
    "Now load the file to ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15ba43-29bf-4468-8bae-e32588a5d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = phc.hdf5.load_photon_hdf5('testout.hdf5')\n",
    "d = phc.hdf5.dict_from_group(h5file.root)\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8622c2-a198-497f-b527-bc9379a2011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['photon_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72b116-6cf5-4bf6-9ab7-df028f07ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['setup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fcc8a1-e766-4921-bc53-c15e9dd766d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
